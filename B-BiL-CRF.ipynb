{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "current-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torchcrf import CRF\n",
    "from typing import Optional\n",
    "from module import report\n",
    "from module import Data_Agument\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from datasets import Dataset\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from livelossplot import PlotLosses\n",
    "from tqdm.notebook import tqdm\n",
    "from module import pytorchtools_Bert\n",
    "label_list = [\n",
    "'<pad>',\n",
    "'O',\n",
    "'B-RightSpeaker',   \n",
    "'B-Speaker',\n",
    "'B-LeftSpeaker',\n",
    "'B-Unknown',\n",
    "'I-RightSpeaker',\n",
    "'I-Speaker',\n",
    "'I-LeftSpeaker',\n",
    "'I-Unknown',\n",
    "\"<EOS>\",\n",
    "\"<BOS>\"\n",
    "]\n",
    "label_encoding_dict = {\n",
    "'<pad>':0,\n",
    "'O': 1,\n",
    "'B-RightSpeaker': 2,   \n",
    "'B-Speaker': 3,\n",
    "'B-LeftSpeaker': 4,\n",
    "'B-Unknown': 5,\n",
    "'I-RightSpeaker': 6,\n",
    "'I-Speaker': 7,\n",
    "'I-LeftSpeaker': 8,\n",
    "'I-Unknown': 9,\n",
    "\"<EOS>\":10,\n",
    "\"<BOS>\":11\n",
    "}\n",
    "task = \"ner\" \n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "batch_size = 32\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "\n",
    "def get_all_tokens_and_ner_tags(directory):\n",
    "    return pd.concat([get_tokens_and_ner_tags(directory) ]).reset_index().drop('index', axis=1)\n",
    "\n",
    "\n",
    "def get_tokens_and_ner_tags(filename):\n",
    "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        split_list = [list(y) for x, y in itertools.groupby(lines, lambda z: z == '\\n') if not x]\n",
    "        tokens = [[x.split(' ')[0] for x in y] for y in split_list]\n",
    "        entities = [[x.split(' ')[1][:-1] for x in y] for y in split_list] \n",
    "    return pd.DataFrame({'tokens': tokens, 'ner_tags': entities})\n",
    "\n",
    "\n",
    "def get_un_token_dataset(directory, Rondom):\n",
    "    if Rondom:\n",
    "        df, AFTER_NAME_LIST_APPEAR_1, AFTER_NAME_LIST__OVER_1 = Data_Agument.get_Data_Agument(directory)\n",
    "        print(len(AFTER_NAME_LIST_APPEAR_1), len(AFTER_NAME_LIST__OVER_1))\n",
    "    else:\n",
    "        df = get_all_tokens_and_ner_tags(directory)\n",
    "        for i in range(len(df)):\n",
    "            df.ner_tags[i] = [\"O\" if d == \"Out\" else d for d in df.ner_tags[i]]\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.3)\n",
    "    df_test, df_val = train_test_split(df_test, test_size=0.5)\n",
    "    test_dataset = Dataset.from_pandas(df_test.reset_index(drop=True))\n",
    "    train_dataset = Dataset.from_pandas(df_train.reset_index(drop=True))\n",
    "    val_dataset = Dataset.from_pandas(df_val.reset_index(drop=True))\n",
    "\n",
    "    return (df,train_dataset,test_dataset,val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78430afb-ff21-425b-8c15-0a285aa556a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "verified-endorsement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890 1770\n"
     ]
    }
   ],
   "source": [
    "df, train_dataset, test_dataset, val_dataset = get_un_token_dataset(\"./DirectQuote/data/truecased.txt\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brazilian-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = 'path/model_B_BiL_CRF_path.pth'\n",
    "path_model = \"model_bert/BL_CRF.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "documented-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    label_all_tokens = True\n",
    "    tokenized_inputs = tokenizer(list(examples[\"tokens\"]), truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        EOS_check=True\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None and EOS_check is True:\n",
    "                label_ids.append(10)\n",
    "                EOS_check=False\n",
    "            elif word_idx is None and EOS_check is False:\n",
    "                label_ids.append(11)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_encoding_dict[label[word_idx]])\n",
    "            else:\n",
    "                label_ids.append(label_encoding_dict[label[word_idx]] if label_all_tokens else -101)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "        \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crucial-greek",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7791d8404cf1410f88fe41baef2367b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38580f97b3584656835fa1129ba9bd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3971c653cba6419998bd9b5ce6659d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenized_datasets = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_tokenized_datasets = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "val_tokenized_datasets = val_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "speaking-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_ids = torch.tensor(self.dataset[index][\"input_ids\"])\n",
    "        token_type_ids = torch.tensor(self.dataset[index][\"token_type_ids\"])\n",
    "        attention_mask = torch.tensor(self.dataset[index][\"attention_mask\"])\n",
    "        labels = torch.tensor(self.dataset[index][\"labels\"])\n",
    "        return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"token_type_ids\": token_type_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bizarre-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list,M_list,type_list = [], [],[],[]\n",
    "    for (B) in batch:\n",
    "        _text=B[\"input_ids\"]\n",
    "        _label=B[\"labels\"]\n",
    "        _mask=B[\"attention_mask\"]\n",
    "        _type=B[\"token_type_ids\"]\n",
    "        label_list.append(_label)\n",
    "        text_list.append(_text)\n",
    "        M_list.append(_mask)\n",
    "        type_list.append(_type)\n",
    "    text_list = torch.nn.utils.rnn.pad_sequence(text_list, batch_first=True, padding_value=0)\n",
    "    label_list = torch.nn.utils.rnn.pad_sequence(label_list, batch_first=True, padding_value=0)\n",
    "    M_list = torch.nn.utils.rnn.pad_sequence(M_list, batch_first=True, padding_value=0)\n",
    "    type_list = torch.nn.utils.rnn.pad_sequence(type_list, batch_first=True, padding_value=0)\n",
    "    return {\n",
    "        \"input_ids\": text_list,\n",
    "        \"token_type_ids\": type_list,\n",
    "        \"attention_mask\": M_list,\n",
    "        \"labels\": label_list\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "particular-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_for_loader = CreateDataset(train_tokenized_datasets)\n",
    "dataset_val_for_loader = CreateDataset(val_tokenized_datasets)\n",
    "dataset_test_for_loader = CreateDataset(test_tokenized_datasets)\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train_for_loader,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val_for_loader,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test_for_loader,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "dataloaders_dict = {\"train\": dataloader_train, \"val\": dataloader_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "empirical-pressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig\n",
    "config = BertConfig()\n",
    "config.num_labels = len(label_list)\n",
    "print(config.initializer_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "290cae28-29a7-4761-ba1a-ebb2b67cc15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(model_checkpoint,add_pooling_layer=False, output_attentions=True, output_hidden_states=True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        token_type_ids,\n",
    "        attention_mask,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        return_dict: Optional[bool] = None\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else config.use_return_dict\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        return TokenClassifierOutput(\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85afc50f-6839-4bae-8d58-f6c79bdb87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, config, batch_size, device):\n",
    "        super(BERT_BiLSTM_CRF, self).__init__()\n",
    "        self.num_labels = config.num_labels\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.bert = BERT().to(device)\n",
    "        self.BiLSTM = nn.LSTM(input_size=self.hidden_size,\n",
    "                              hidden_size=self.hidden_size,\n",
    "                              batch_first=True,\n",
    "                              bidirectional=True)\n",
    "        self.crf = CRF(self.num_labels, batch_first=True)\n",
    "        self.hidden2label = nn.Linear(self.hidden_size*2, self.num_labels)\n",
    "\n",
    "    def _get_bert_features(self, input_ids, token_type_ids, attention_mask, labels, return_dict):\n",
    "        bert_seq_out = self.bert(\n",
    "            input_ids=input_ids, \n",
    "            token_type_ids=None,\n",
    "            attention_mask=attention_mask, \n",
    "            labels=labels,\n",
    "            return_dict=True)\n",
    "        bert_seq_out = self.dropout(bert_seq_out[\"hidden_states\"][-1])\n",
    "        bilstm_seq_out, _ = self.BiLSTM(bert_seq_out, None)\n",
    "        bilstm_seq_out = self.dropout(bilstm_seq_out)\n",
    "        bert_bilstm_feats = self.hidden2label(bilstm_seq_out)\n",
    "        return bert_bilstm_feats\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask, labels, return_dict):\n",
    "\n",
    "        bert_bilstm_feats = self._get_bert_features(\n",
    "            input_ids=input_ids, \n",
    "            token_type_ids=None,\n",
    "            attention_mask=attention_mask, \n",
    "            labels=labels,\n",
    "            return_dict=True)\n",
    "        log_likelihood = self.crf(bert_bilstm_feats, labels, mask = attention_mask.bool())\n",
    "        seq_tags = self.crf.decode(bert_bilstm_feats, mask = attention_mask.bool())\n",
    "        return log_likelihood, seq_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adcff626-9f52-4142-8e02-94501da1c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = label_list\n",
    "label_map = {label: i for i,label in enumerate(label_list)}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c96ec0e3-d314-457c-9fbc-a78b401be8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "start_label_id = label_map[\"<BOS>\"]\n",
    "stop_label_id = label_map[\"<EOS>\"]\n",
    "model = BERT_BiLSTM_CRF(config, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "897bdfba-c53e-4bec-be3f-c79177650282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5a300f1-bd89-464d-86a1-1eef52f38261",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_params = [p for n, p in model_params if \"bert\" in n]\n",
    "class_params = [p for n, p in model_params if \"hidden2label\" in n]\n",
    "lstm_params = [p for n, p in model_params if \"BiLSTM\" in n] \n",
    "crf_params = [p for n, p in model_params if \"crf\" in n] \n",
    "params = [\n",
    "    {'params': bert_params, 'lr': 0.000001},\n",
    "    {'params': lstm_params, 'lr': 0.00001,'weight_decacy_rate':0.0001},\n",
    "    {'params': class_params, 'lr': 0.001},\n",
    "    {'params': crf_params, 'lr': 0.01}\n",
    "]\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.bert.bert.encoder.layer[-10:].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.crf.parameters():\n",
    "    param.requires_grad = True \n",
    "for param in model.BiLSTM.parameters():\n",
    "    param.requires_grad = True \n",
    "for param in model.hidden2label.parameters():\n",
    "    param.requires_grad = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d908edfd-4cae-491a-81d8-f6ba2f060493",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "patience = 15\n",
    "early_stopping = pytorchtools_Bert.EarlyStopping(patience=patience, verbose=True,path=path_checkpoint)\n",
    "model.to(device)\n",
    "liveloss = PlotLosses()\n",
    "optimizer = torch.optim.Adam(params)\n",
    "def train_model(net, dataloaders_dict, num_epochs):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "    logs = {}\n",
    "    lrs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            L2,P2=[],[]\n",
    "\n",
    "            for batch in tqdm((dataloaders_dict[phase])):\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output = net(input_ids=input_ids,\n",
    "                                 token_type_ids=None,\n",
    "                                 attention_mask=attention_mask,\n",
    "                                 labels=labels,\n",
    "                                 return_dict=True)\n",
    "                    loss = -output[0]\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "                        optimizer.step()\n",
    "                    epoch_loss += loss.item()\n",
    "            if phase == 'val':\n",
    "                logs['val_loss'] = epoch_loss/ len(dataloaders_dict[phase].dataset)\n",
    "            else:\n",
    "                logs['loss'] = epoch_loss/ len(dataloaders_dict[phase].dataset)\n",
    "        if phase == 'val':\n",
    "            early_stopping(epoch_loss/ len(dataloaders_dict[phase].dataset),net) \n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early Stopping\")\n",
    "                return net\n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()\n",
    "        #lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "        #scheduler.step()\n",
    "        #plt.plot(lrs)\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4704865e-9aaf-4c86-ab5c-d40c72326daf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    0.341, max:   13.600, cur:    0.341)\n",
      "\tvalidation       \t (min:    0.955, max:    3.815, cur:    1.267)\n",
      "29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23fbe0dec774a509ad2a744154287c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3557fca8f85743ac8668b587b70b3084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 15 out of 15\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "net_trained = train_model(model, dataloaders_dict, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0f2027-492a-4d5e-8cea-a1c4e5431045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DATA_CLEAN(out, mask):\n",
    "    pre = [label_list[out[i + 1]] for i in range(sum(mask > 0) - 2)]\n",
    "    return report.get_entities(pre)\n",
    "\n",
    "\n",
    "def evaluate_model(batch_entities_list, batch_entities_predicted_list, type_id=None):\n",
    "    num_entities = 0\n",
    "    num_predictions = 0\n",
    "    num_correct = 0\n",
    "    for entities_list, entities_predicted_list in zip(batch_entities_list, batch_entities_predicted_list):\n",
    "        for entities, entities_predicted in zip(entities_list, entities_predicted_list):\n",
    "            if type_id:\n",
    "                entities = [e for e in entities if e[0] == type_id]\n",
    "                entities_predicted = [\n",
    "                    e for e in entities_predicted if e[0] == type_id\n",
    "                ]\n",
    "\n",
    "            get_span_type = lambda e: (e[1], e[2], e[0])\n",
    "            set_entities = set(get_span_type(e) for e in entities)\n",
    "            set_entities_predicted = set(get_span_type(e) for e in entities_predicted)\n",
    "            num_entities += len(entities)\n",
    "            num_predictions += len(entities_predicted)\n",
    "            num_correct += len(set_entities & set_entities_predicted)\n",
    "\n",
    "    precision = num_correct/num_predictions\n",
    "    recall = num_correct/num_entities\n",
    "    f_value = 2*precision*recall/(precision+recall)\n",
    "\n",
    "    result = {\n",
    "        'num_entities': num_entities,\n",
    "        'num_predictions': num_predictions,\n",
    "        'num_correct': num_correct,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f_value': f_value\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def eval_model(label, lists):\n",
    "    eval_label_encoding_dict = {\n",
    "        \"Speaker\": \"Speaker\",\n",
    "        \"Quoat\": \"Quoat\"\n",
    "    }\n",
    "    eval_df = pd.DataFrame()\n",
    "    for k, v in eval_label_encoding_dict.items():\n",
    "        eval_res = evaluate_model(label, lists, type_id=v)\n",
    "        eval_df[k] = eval_res.values()\n",
    "\n",
    "    eval_res_all = evaluate_model(label, lists, type_id=None)\n",
    "    eval_df[\"ALL\"] = eval_res_all.values()\n",
    "\n",
    "    eval_df.index = eval_res_all.keys()\n",
    "    return eval_df\n",
    "\n",
    "\n",
    "def mat3(datasets, MO):\n",
    "    L2, P2 = [], []\n",
    "    MO.eval()\n",
    "    MO.to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm((datasets)):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            output = MO(input_ids=input_ids, token_type_ids=None, \n",
    "                        attention_mask=attention_mask, \n",
    "                        labels=labels,\n",
    "                        return_dict=True)\n",
    "            out_list = map(DATA_CLEAN, output[1], attention_mask.cpu().numpy().copy())\n",
    "            out_label = map(DATA_CLEAN, labels, attention_mask.cpu().numpy().copy())\n",
    "            P2.append(list(out_list))\n",
    "            L2.append(list(out_label))\n",
    "\n",
    "    return L2, P2, eval_model(L2, P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc729c20-7d19-4c81-b8a3-1cb320e0719f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e8381c895445ed946bb3c69b03e578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L, P, result = mat3(dataloader_test, torch.load(path_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7453dfbf-905a-461e-878a-8c6dc0f0a06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Quoat</th>\n",
       "      <th>ALL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_entities</th>\n",
       "      <td>1156.000000</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>1953.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_predictions</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_correct</th>\n",
       "      <td>1043.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.850734</td>\n",
       "      <td>0.868188</td>\n",
       "      <td>0.857568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.902249</td>\n",
       "      <td>0.859473</td>\n",
       "      <td>0.884793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_value</th>\n",
       "      <td>0.875735</td>\n",
       "      <td>0.863808</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Speaker       Quoat          ALL\n",
       "num_entities     1156.000000  797.000000  1953.000000\n",
       "num_predictions  1226.000000  789.000000  2015.000000\n",
       "num_correct      1043.000000  685.000000  1728.000000\n",
       "precision           0.850734    0.868188     0.857568\n",
       "recall              0.902249    0.859473     0.884793\n",
       "f_value             0.875735    0.863808     0.870968"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb240dfd-2b63-497e-bb4e-79ec0f7beadc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Quoat</th>\n",
       "      <th>ALL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_entities</th>\n",
       "      <td>1156.000000</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>1953.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_predictions</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_correct</th>\n",
       "      <td>1043.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>1728.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.850734</td>\n",
       "      <td>0.868188</td>\n",
       "      <td>0.857568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.902249</td>\n",
       "      <td>0.859473</td>\n",
       "      <td>0.884793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_value</th>\n",
       "      <td>0.875735</td>\n",
       "      <td>0.863808</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Speaker       Quoat          ALL\n",
       "num_entities     1156.000000  797.000000  1953.000000\n",
       "num_predictions  1226.000000  789.000000  2015.000000\n",
       "num_correct      1043.000000  685.000000  1728.000000\n",
       "precision           0.850734    0.868188     0.857568\n",
       "recall              0.902249    0.859473     0.884793\n",
       "f_value             0.875735    0.863808     0.870968"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7646f68-ff49-448f-8ceb-d24b8ac3bb64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "current-groove",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from typing import Optional\n",
    "from module import report\n",
    "from module import Data_Agument\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from datasets import Dataset\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "#from transformers import DataCollatorForTokenClassification\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss,NLLLoss\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from livelossplot import PlotLosses\n",
    "from tqdm.notebook import tqdm\n",
    "from module import pytorchtools_Bert\n",
    "\"\"\"\n",
    "[[0,-1,-1,-1,-1,-1,-1,-1,-1,-1,0,-1],\n",
    "[0,0,0,0,0,0,-1,-1,-1,-1,0,-1],\n",
    "[0,0,0,0,0,0,0,-1,-1,-1,0,-1],\n",
    "[0,0,0,0,0,0,-1,0,-1,-1,0,-1],\n",
    "[0,0,0,0,0,0,-1,-1,0,-1,0,-1],\n",
    "[0,0,0,0,0,0,-1,-1,-1,0,0,-1],\n",
    "\n",
    "[0,0,0,0,0,0,0,-1,-1,-1,0,-1],\n",
    "[0,0,0,0,0,0,-1,0,-1,-1,0.-1],\n",
    "[0,0,0,0,0,0,-1,-1,0,-1,0,-1],\n",
    "[0,0,0,0,0,0,-1,-1,-1,0,0,-1],\n",
    "[-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1],\n",
    "[-1,0,0,0,0,0,-1,-1,-1,-1,-1,-1]]\n",
    "\"\"\"\n",
    "label_list = [\n",
    "'<pad>',\n",
    "'O',\n",
    "'B-RightSpeaker',   \n",
    "'B-Speaker',\n",
    "'B-LeftSpeaker',\n",
    "'B-Unknown',\n",
    "'I-RightSpeaker',\n",
    "'I-Speaker',\n",
    "'I-LeftSpeaker',\n",
    "'I-Unknown',\n",
    "\"<EOS>\",\n",
    "\"<BOS>\"\n",
    "]\n",
    "label_encoding_dict = {\n",
    "'<pad>':0,\n",
    "'O': 1,\n",
    "'B-RightSpeaker': 2,   \n",
    "'B-Speaker': 3,\n",
    "'B-LeftSpeaker': 4,\n",
    "'B-Unknown': 5,\n",
    "'I-RightSpeaker': 6,\n",
    "'I-Speaker': 7,\n",
    "'I-LeftSpeaker': 8,\n",
    "'I-Unknown': 9,\n",
    "\"<EOS>\":10,\n",
    "\"<BOS>\":11\n",
    "}\n",
    "task = \"ner\" \n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "batch_size = 32\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "\n",
    "def get_all_tokens_and_ner_tags(directory):\n",
    "    return pd.concat([get_tokens_and_ner_tags(directory) ]).reset_index().drop('index', axis=1)\n",
    "\n",
    "\n",
    "def get_tokens_and_ner_tags(filename):\n",
    "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        split_list = [list(y) for x, y in itertools.groupby(lines, lambda z: z == '\\n') if not x]\n",
    "        tokens = [[x.split(' ')[0] for x in y] for y in split_list]\n",
    "        entities = [[x.split(' ')[1][:-1] for x in y] for y in split_list] \n",
    "    return pd.DataFrame({'tokens': tokens, 'ner_tags': entities})\n",
    "\n",
    "\n",
    "def get_un_token_dataset(directory, Rondom):\n",
    "    if Rondom:\n",
    "        df, AFTER_NAME_LIST_APPEAR_1, AFTER_NAME_LIST__OVER_1 = Data_Agument.get_Data_Agument(directory)\n",
    "        print(len(AFTER_NAME_LIST_APPEAR_1), len(AFTER_NAME_LIST__OVER_1))\n",
    "    else:\n",
    "        df = get_all_tokens_and_ner_tags(directory)\n",
    "        for i in range(len(df)):\n",
    "            df.ner_tags[i] = [\"O\" if d == \"Out\" else d for d in df.ner_tags[i]]\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.3)\n",
    "    df_test, df_val = train_test_split(df_test, test_size=0.5)\n",
    "    test_dataset = Dataset.from_pandas(df_test.reset_index(drop=True))\n",
    "    train_dataset = Dataset.from_pandas(df_train.reset_index(drop=True))\n",
    "    val_dataset = Dataset.from_pandas(df_val.reset_index(drop=True))\n",
    "\n",
    "    return (df,train_dataset,test_dataset,val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "verified-endorsement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884 1776\n"
     ]
    }
   ],
   "source": [
    "df, train_dataset, test_dataset, val_dataset = get_un_token_dataset(\"./DirectQuote/data/truecased.txt\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brazilian-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = 'path/model_B_BiL_path.pth'\n",
    "path_model = \"model_bert/BL_CRF.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "documented-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    label_all_tokens = True\n",
    "    tokenized_inputs = tokenizer(list(examples[\"tokens\"]), truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        EOS_check=True\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None and EOS_check is True:\n",
    "                label_ids.append(10)\n",
    "                EOS_check=False\n",
    "            elif word_idx is None and EOS_check is False:\n",
    "                label_ids.append(11)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_encoding_dict[label[word_idx]])\n",
    "            else:\n",
    "                label_ids.append(label_encoding_dict[label[word_idx]] if label_all_tokens else -101)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "        \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crucial-greek",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd08f089cd2740cdb65ec91cb96ce756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6461eff381ff4757b0bf4adcca2373af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064d2d4a751d42418cbacd5f54fe17ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenized_datasets = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_tokenized_datasets = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "val_tokenized_datasets = val_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "speaking-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_ids = torch.tensor(self.dataset[index][\"input_ids\"])\n",
    "        token_type_ids = torch.tensor(self.dataset[index][\"token_type_ids\"])\n",
    "        attention_mask = torch.tensor(self.dataset[index][\"attention_mask\"])\n",
    "        labels = torch.tensor(self.dataset[index][\"labels\"])\n",
    "        return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"token_type_ids\": token_type_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bizarre-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list,M_list,type_list = [], [],[],[]\n",
    "    for (B) in batch:\n",
    "        _text=B[\"input_ids\"]\n",
    "        _label=B[\"labels\"]\n",
    "        _mask=B[\"attention_mask\"]\n",
    "        _type=B[\"token_type_ids\"]\n",
    "        label_list.append(_label)\n",
    "        text_list.append(_text)\n",
    "        M_list.append(_mask)\n",
    "        type_list.append(_type)\n",
    "    text_list = torch.nn.utils.rnn.pad_sequence(text_list, batch_first=True, padding_value=0)\n",
    "    label_list = torch.nn.utils.rnn.pad_sequence(label_list, batch_first=True, padding_value=0)\n",
    "    M_list = torch.nn.utils.rnn.pad_sequence(M_list, batch_first=True, padding_value=0)\n",
    "    type_list = torch.nn.utils.rnn.pad_sequence(type_list, batch_first=True, padding_value=0)\n",
    "    return {\n",
    "        \"input_ids\": text_list,\n",
    "        \"token_type_ids\": type_list,\n",
    "        \"attention_mask\": M_list,\n",
    "        \"labels\": label_list\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "particular-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_for_loader = CreateDataset(train_tokenized_datasets)\n",
    "dataset_val_for_loader = CreateDataset(val_tokenized_datasets)\n",
    "dataset_test_for_loader = CreateDataset(test_tokenized_datasets)\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train_for_loader,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val_for_loader,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test_for_loader,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "dataloaders_dict = {\"train\": dataloader_train, \"val\": dataloader_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "empirical-pressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig\n",
    "config = BertConfig()\n",
    "config.num_labels = len(label_list)\n",
    "print(config.initializer_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "290cae28-29a7-4761-ba1a-ebb2b67cc15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(model_checkpoint,add_pooling_layer=False, output_attentions=True, output_hidden_states=True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        token_type_ids,\n",
    "        attention_mask,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        ):\n",
    "      \n",
    "        return_dict = return_dict if return_dict is not None else config.use_return_dict\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "    \n",
    "        return TokenClassifierOutput(\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85afc50f-6839-4bae-8d58-f6c79bdb87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_BiLSTM(nn.Module):\n",
    "    def __init__(self, config, batch_size, device):\n",
    "        super(BERT_BiLSTM, self).__init__()\n",
    "        self.num_labels = config.num_labels\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.bert = BERT()\n",
    "        self.BiLSTM = nn.LSTM(input_size=self.hidden_size,\n",
    "                              hidden_size=self.hidden_size,\n",
    "                              batch_first=True,\n",
    "                              bidirectional=True)\n",
    "        self.hidden2label = nn.Linear(self.hidden_size*2, self.num_labels)\n",
    "\n",
    "    def _get_bert_features(self, input_ids, token_type_ids, attention_mask, labels, return_dict):\n",
    "        bert_seq_out = self.bert(\n",
    "            input_ids=input_ids, \n",
    "            token_type_ids=None,\n",
    "            attention_mask=attention_mask, \n",
    "            labels=labels,\n",
    "            return_dict=True)\n",
    "        bert_seq_out = self.dropout(bert_seq_out[\"hidden_states\"][-1])\n",
    "        bilstm_seq_out, _ = self.BiLSTM(bert_seq_out, None)\n",
    "        bilstm_seq_out = self.dropout(bilstm_seq_out)\n",
    "        bert_bilstm_feats = self.hidden2label(bilstm_seq_out)\n",
    "        return bert_bilstm_feats\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask, labels, return_dict):\n",
    "\n",
    "        bert_bilstm_feats = self._get_bert_features(\n",
    "            input_ids=input_ids, \n",
    "            token_type_ids=None,\n",
    "            attention_mask=attention_mask, \n",
    "            labels=labels,\n",
    "            return_dict=True)\n",
    "        loss_fct = CrossEntropyLoss(ignore_index=0)\n",
    "        loss = loss_fct(bert_bilstm_feats.view(-1, self.num_labels), labels.view(-1))\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=bert_bilstm_feats,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adcff626-9f52-4142-8e02-94501da1c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = label_list\n",
    "label_map = {label: i for i,label in enumerate(label_list)}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c96ec0e3-d314-457c-9fbc-a78b401be8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "start_label_id = label_map[\"<BOS>\"]\n",
    "stop_label_id = label_map[\"<EOS>\"]\n",
    "model = BERT_BiLSTM(config, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "897bdfba-c53e-4bec-be3f-c79177650282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5a300f1-bd89-464d-86a1-1eef52f38261",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_params = [p for n, p in model_params if \"bert\" in n]\n",
    "class_params = [p for n, p in model_params if \"hidden2label\" in n]\n",
    "lstm_params = [p for n, p in model_params if \"BiLSTM\" in n] \n",
    "params = [\n",
    "    {'params': bert_params, 'lr': 0.00001},\n",
    "    {'params': lstm_params, 'lr': 0.0001,'weight_decacy_rate':0.00001},\n",
    "    {'params': class_params, 'lr': 0.001}\n",
    "]\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.bert.bert.encoder.layer[-7:].parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in model.BiLSTM.parameters():\n",
    "    param.requires_grad = True \n",
    "for param in model.hidden2label.parameters():\n",
    "    param.requires_grad = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d908edfd-4cae-491a-81d8-f6ba2f060493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "patience = 5\n",
    "early_stopping = pytorchtools_Bert.EarlyStopping(patience=patience, verbose=True,path=path_checkpoint)\n",
    "model.to(device)\n",
    "liveloss = PlotLosses()\n",
    "optimizer = torch.optim.Adam(params)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2,4], gamma=0.1)\n",
    "def train_model(net, dataloaders_dict, num_epochs):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "    logs = {}\n",
    "    lrs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            L2,P2=[],[]\n",
    "\n",
    "            for batch in tqdm((dataloaders_dict[phase])):\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output = net(input_ids=input_ids,\n",
    "                                 token_type_ids=None,\n",
    "                                 attention_mask=attention_mask,\n",
    "                                 labels=labels,\n",
    "                                 return_dict=True)\n",
    "                    loss = output[0]\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "                        optimizer.step()\n",
    "                    epoch_loss += loss.item()*batch_size\n",
    "            if phase == 'val':\n",
    "                logs['val_loss'] = epoch_loss/ len(dataloaders_dict[phase].dataset)\n",
    "            else:\n",
    "                logs['loss'] = epoch_loss/ len(dataloaders_dict[phase].dataset)\n",
    "        if phase == 'val':\n",
    "            early_stopping(epoch_loss/ len(dataloaders_dict[phase].dataset),net) \n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early Stopping\")\n",
    "                return net\n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()\n",
    "        lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "        scheduler.step()\n",
    "        plt.plot(lrs)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4704865e-9aaf-4c86-ab5c-d40c72326daf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    0.130, max:    0.356, cur:    0.131)\n",
      "\tvalidation       \t (min:    0.144, max:    0.174, cur:    0.147)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8ae1a8778a4376a8626ec6b425e42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03be91ed9d2e4d9ca5fe56325a22e66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "net_trained = train_model(model, dataloaders_dict, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8278ecd6-9926-45cd-b740-2e594011f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(scores_bert, num_entity_type, penalty=10000):\n",
    "        m = num_entity_type\n",
    "        penalty_matrix = np.zeros([m, m])\n",
    "        \"\"\"\n",
    "        for x in range(1,5):\n",
    "            for y in range(1,9):\n",
    "                if (x+4 == y):\n",
    "                    penalty_matrix[y,x]=penalty\n",
    "        \"\"\"\n",
    "        for x in range(6,10):\n",
    "            for y in range(0,10):\n",
    "                if (x==y or x == 4+y):\n",
    "                    penalty_matrix[y,x]=0\n",
    "                else:\n",
    "                    penalty_matrix[y,x]=1000\n",
    "        path = [ [i] for i in range(m) ]\n",
    "        scores_path = scores_bert[0] - penalty_matrix[0,:]\n",
    "        scores_bert = scores_bert[1:]\n",
    "        for scores in scores_bert:\n",
    "            assert len(scores) == num_entity_type \n",
    "            score_matrix = np.array(scores_path).reshape(-1,1) \\\n",
    "                + np.array(scores).reshape(1,-1) \\\n",
    "                - penalty_matrix\n",
    "            scores_path = score_matrix.max(axis=0)\n",
    "            argmax = score_matrix.argmax(axis=0)\n",
    "            path_new = []\n",
    "            for i, idx in enumerate(argmax):\n",
    "                path_new.append( path[idx] + [i] )\n",
    "            path = path_new\n",
    "        labels_optimal = path[np.argmax(scores_path)]\n",
    "        return labels_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "310d306b-e1f6-494c-93a5-eb34cd7d3708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method CRF._viterbi_decode of CRF(num_tags=12)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchcrf import CRF\n",
    "CRF(len(label_list), batch_first=True)._viterbi_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c0f2027-492a-4d5e-8cea-a1c4e5431045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DATA_CLEAN(out, mask):\n",
    "    pre = [label_list[out[i + 1]] for i in range(sum(mask > 0) - 2)]\n",
    "    return (report.get_entities(pre), pre)\n",
    "\n",
    "\n",
    "def evaluate_model(batch_entities_list, batch_entities_predicted_list, type_id=None):\n",
    "    num_entities = 0\n",
    "    num_predictions = 0\n",
    "    num_correct = 0 \n",
    "    for entities_list, entities_predicted_list in zip(batch_entities_list, batch_entities_predicted_list):\n",
    "        for entities, entities_predicted in zip(entities_list, entities_predicted_list):\n",
    "            if type_id:\n",
    "                entities = [e for e in entities if e[0] == type_id]\n",
    "                entities_predicted = [\n",
    "                    e for e in entities_predicted if e[0] == type_id\n",
    "                ]\n",
    "\n",
    "            get_span_type = lambda e: (e[1], e[2], e[0])\n",
    "            set_entities = set(get_span_type(e) for e in entities)\n",
    "            set_entities_predicted = set(get_span_type(e) for e in entities_predicted)\n",
    "            num_entities += len(entities)\n",
    "            num_predictions += len(entities_predicted)\n",
    "            num_correct += len(set_entities & set_entities_predicted)\n",
    "\n",
    "    precision = num_correct/num_predictions\n",
    "    recall = num_correct/num_entities\n",
    "    f_value = 2*precision*recall/(precision+recall)\n",
    "\n",
    "    result = {\n",
    "        'num_entities': num_entities,\n",
    "        'num_predictions': num_predictions,\n",
    "        'num_correct': num_correct,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f_value': f_value\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def eval_model(label, lists):\n",
    "    eval_label_encoding_dict = {\n",
    "        \"Speaker\": \"Speaker\",\n",
    "        \"Quoat\": \"Quoat\"\n",
    "    }\n",
    "    eval_df = pd.DataFrame()\n",
    "    for k, v in eval_label_encoding_dict.items():\n",
    "        eval_res = evaluate_model(label, lists, type_id=v)\n",
    "        eval_df[k] = eval_res.values()\n",
    "\n",
    "    eval_res_all = evaluate_model(label, lists, type_id=None)\n",
    "    eval_df[\"ALL\"] = eval_res_all.values()\n",
    "\n",
    "    eval_df.index = eval_res_all.keys()\n",
    "    return eval_df\n",
    "\n",
    "\n",
    "def mat3(datasets, MO):\n",
    "    crf=CRF(len(label_list), batch_first=True)\n",
    "    #crf.transitions=nn.Parameter(torch.empty(12, 12))\n",
    "    #crf.reset_parameters()\n",
    "    print(crf.transitions)\n",
    "    L2, P2 = [], []\n",
    "    MO.eval()\n",
    "    MO.to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm((datasets)):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            output = MO(input_ids=input_ids, token_type_ids=None, \n",
    "                        attention_mask=attention_mask, \n",
    "                        labels=labels,\n",
    "                        return_dict=True)\n",
    "            preT = crf.decode(output.logits.to(\"cpu\"), attention_mask.bool().to(\"cpu\"))\n",
    "            out_list = map(DATA_CLEAN,\n",
    "                                preT,\n",
    "                                attention_mask.cpu().numpy().copy())\n",
    "            out_label = map(DATA_CLEAN,\n",
    "                                 labels,\n",
    "                                 attention_mask.cpu().numpy().copy())\n",
    "            #print([pd.DataFrame({'pre': p[1], 'true': l[1]}) for p, l in zip(list(out_list), list(out_label))])\n",
    "            P2.append([o[0] for o in list(out_list)])\n",
    "            L2.append([o[0] for o in list(out_label)])\n",
    "\n",
    "\n",
    "    return L2, P2, eval_model(L2, P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc729c20-7d19-4c81-b8a3-1cb320e0719f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0853,  0.0594, -0.0544,  0.0613,  0.0021, -0.0264,  0.0428,  0.0788,\n",
      "         -0.0299, -0.0608, -0.0009,  0.0851],\n",
      "        [ 0.0204, -0.0337, -0.0572, -0.0180,  0.0109, -0.0403,  0.0905, -0.0964,\n",
      "         -0.0796, -0.0775, -0.0767, -0.0532],\n",
      "        [ 0.0640, -0.0643,  0.0408, -0.0113, -0.0729,  0.0485, -0.0164, -0.0728,\n",
      "         -0.0917,  0.0364, -0.0888, -0.0597],\n",
      "        [-0.0597,  0.0221,  0.0601,  0.0458, -0.0070,  0.0523, -0.0424, -0.0138,\n",
      "         -0.0736,  0.0757,  0.0312,  0.0653],\n",
      "        [ 0.0968,  0.0332,  0.0358,  0.0289,  0.0904, -0.0318,  0.0139,  0.0250,\n",
      "         -0.0387,  0.0649,  0.0041, -0.0152],\n",
      "        [ 0.0163,  0.0792,  0.0237,  0.0871, -0.0771, -0.0192, -0.0709, -0.0727,\n",
      "          0.0186,  0.0848,  0.0403, -0.0257],\n",
      "        [-0.0073,  0.0797,  0.0550, -0.0306,  0.0948, -0.0010, -0.0002, -0.0729,\n",
      "         -0.0529,  0.0716, -0.0070, -0.0640],\n",
      "        [-0.0340, -0.0810, -0.0166, -0.0216,  0.0558,  0.0208, -0.0437,  0.0518,\n",
      "         -0.0373,  0.0324,  0.0552,  0.0383],\n",
      "        [ 0.0059,  0.0682,  0.0018,  0.0665, -0.0628, -0.0986,  0.0873, -0.0692,\n",
      "          0.0844, -0.0635,  0.0890,  0.0738],\n",
      "        [-0.0759, -0.0578,  0.0415,  0.0481, -0.0385,  0.0206,  0.0039,  0.0156,\n",
      "          0.0816, -0.0490,  0.0320, -0.0420],\n",
      "        [-0.0572,  0.0685, -0.0274,  0.0212,  0.0921,  0.0810, -0.0623,  0.0390,\n",
      "          0.0385,  0.0677,  0.0411,  0.0984],\n",
      "        [ 0.0309,  0.0717, -0.0467, -0.0843, -0.0983, -0.0742, -0.0932, -0.0727,\n",
      "          0.0990, -0.0962, -0.0096, -0.0102]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fd55c82cb74beaa99691264194c852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m L, P , RE \u001b[38;5;241m=\u001b[39m \u001b[43mmat3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_checkpoint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [64], line 67\u001b[0m, in \u001b[0;36mmat3\u001b[0;34m(datasets, MO)\u001b[0m\n\u001b[1;32m     65\u001b[0m MO\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm((datasets)):\n\u001b[1;32m     68\u001b[0m         input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     69\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn [6], line 15\u001b[0m, in \u001b[0;36mCreateDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     13\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[index][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     14\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[index][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_ids,\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: token_type_ids,\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: attention_mask,\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels\n\u001b[1;32m     21\u001b[0m }\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:2356\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2355\u001b[0m     \u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:2341\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   2339\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, decoded\u001b[38;5;241m=\u001b[39mdecoded, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2340\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2341\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:509\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    507\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:282\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:311\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 311\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoded:\n\u001b[1;32m    313\u001b[0m         row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:141\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unnest(\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "L, P , RE = mat3(dataloader_test, torch.load(path_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7453dfbf-905a-461e-878a-8c6dc0f0a06e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Quoat</th>\n",
       "      <th>ALL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_entities</th>\n",
       "      <td>1146.000000</td>\n",
       "      <td>818.000000</td>\n",
       "      <td>1964.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_predictions</th>\n",
       "      <td>1288.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>2318.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_correct</th>\n",
       "      <td>1059.000000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>1763.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.822205</td>\n",
       "      <td>0.683495</td>\n",
       "      <td>0.760569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.924084</td>\n",
       "      <td>0.860636</td>\n",
       "      <td>0.897658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_value</th>\n",
       "      <td>0.870173</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.823447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Speaker        Quoat          ALL\n",
       "num_entities     1146.000000   818.000000  1964.000000\n",
       "num_predictions  1288.000000  1030.000000  2318.000000\n",
       "num_correct      1059.000000   704.000000  1763.000000\n",
       "precision           0.822205     0.683495     0.760569\n",
       "recall              0.924084     0.860636     0.897658\n",
       "f_value             0.870173     0.761905     0.823447"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "197e22a7-f8a3-4dfd-95e9-694c852575dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0, -1],\n",
       "        [ 0,  0,  0,  0,  0,  0, -1, -1, -1, -1,  0, -1]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([\n",
    "    [0,-1,-1,-1,-1,-1,-1,-1,-1,-1,0,-1],\n",
    "    [0,0,0,0,0,0,-1,-1,-1,-1,0,-1],\n",
    "    [0,0,0,0,0,0,0,-1,-1,-1,0,-1],\n",
    "    [0,0,0,0,0,0,-1,0,-1,-1,0,-1],\n",
    "    [0,0,0,0,0,0,-1,-1,0,-1,0,-1],\n",
    "    [0,0,0,0,0,0,-1,-1,-1,0,0,-1],\n",
    "    [0,0,0,0,0,0,0,-1,-1,-1,0,-1],\n",
    "    [0,0,0,0,0,0,-1,0,-1,-1,0.-1],\n",
    "    [0,0,0,0,0,0,-1,-1,0,-1,0,-1],\n",
    "    [0,0,0,0,0,0,-1,-1,-1,0,0,-1],\n",
    "    [-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1],\n",
    "    [-1,0,0,0,0,0,-1,-1,-1,-1,-1,-1]\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "907ab3c6-eceb-4764-bbf6-10d9b9514a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  2,  3],\n",
       "        [ 4,  5,  6]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([[-1, 2, 3], [4, 5, 6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b05a45-8607-4981-83e0-e0eb31ab239d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
